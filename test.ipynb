{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your code (shapes and values of returned arrays)\n",
    "\n",
    "This notebook provides you some basic testing codes to check your implementation. Note that passing the tests given here doesn't necessarily mean that you have implemented everything correctly. If you cannot import edited .py files to this notebook, please consult E6 ipynb file for further instruction.\n",
    "\n",
    "Once you pass all the tests, go ahead and play with E6, E7, and E8 ipynb files. If everything's implemented correctly, you should be able to train neural network models. You can verify that by observing the train and test errors, as well as graphs given in E7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary modules \n",
    "from model import NeuralNetwork\n",
    "import numpy as np\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check shapes of numpy arrays\n",
    "In this part, below cells of codes will test the shapes of returned arrays from functions you implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from layer import FCLayer\n",
    "in_dim, out_dim, num_sample = 2, 4, 10\n",
    "x = np.ones((num_sample, in_dim))\n",
    "\n",
    "nn = NeuralNetwork()\n",
    "nn.add(FCLayer(in_dim, out_dim))\n",
    "layer = nn.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is ok\n"
     ]
    }
   ],
   "source": [
    "pred = nn.predict(x)\n",
    "delta_n = np.random.randn(num_sample, out_dim)\n",
    "delta = layer.backward(delta_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert pred.shape == (num_sample, out_dim), \"Failed method: 'forward'\\tIncorrect output shape.\"\n",
    "assert delta.shape == (num_sample, in_dim), \"Failed method: 'backward\\tShape mismatch\"\n",
    "assert layer.weights.grad.shape == layer.weights.shape, \"Failed method: 'backward'\\tIncorrect dEdW shape\"\n",
    "assert layer.bias.grad.shape == layer.bias.shape, \"Failed method: 'backward'\\tIncorrect dEdb shape\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### activation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Assuming you have correct layer.py\n",
    "from utils import sigmoid_prime, sigmoid\n",
    "from activation import Activation\n",
    "in_dim, hidden_dim, out_dim, num_sample = 2, 8, 4, 10\n",
    "x = np.ones((num_sample, in_dim))\n",
    "\n",
    "nn = NeuralNetwork()\n",
    "nn.add(FCLayer(in_dim, hidden_dim))\n",
    "nn.add(Activation(sigmoid, sigmoid_prime))\n",
    "nn.add(FCLayer(hidden_dim, out_dim))\n",
    "sigmoid_layer = nn.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is ok\n",
      "X is ok\n"
     ]
    }
   ],
   "source": [
    "nn.predict(x)\n",
    "act = nn.layers[-1].input_data\n",
    "delta_n = np.random.randn(num_sample, out_dim)\n",
    "delta_n = nn.layers[-1].backward(delta_n)\n",
    "delta = sigmoid_layer.backward(delta_n)\n",
    "\n",
    "assert act.shape == (num_sample, hidden_dim), \"Failed method: 'forward'\\tIncorrect hidden layer shape.\"\n",
    "assert delta.shape == (num_sample, hidden_dim), \"Failed method: 'backward\\tShape mismatch\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Test MSE loss\n",
    "from loss import MSELoss\n",
    "num_samples = 10\n",
    "pred = np.ones((num_samples, 1))\n",
    "target = np.zeros((num_samples, 1))\n",
    "loss = MSELoss()\n",
    "mse = loss.loss(pred, target)\n",
    "mse_diff = loss.diff_loss(pred, target)\n",
    "\n",
    "assert mse.size == 1, \"Failed method: 'loss' in MSELoss\\tIncorrect loss shape.\"\n",
    "assert mse_diff.shape == pred.shape, \"Failed method: 'diff_loss' in MSELoss\\tIncorrect diff_loss shape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Test Cross-entropy loss\n",
    "from loss import CrossEntropyLoss\n",
    "out_dim = 10\n",
    "pred = np.random.rand(num_samples, out_dim)\n",
    "target = np.eye(num_samples)\n",
    "ce_loss = CrossEntropyLoss()\n",
    "ce = ce_loss.loss(pred, target)\n",
    "ce_diff = ce_loss.diff_loss(pred, target)\n",
    "\n",
    "assert ce.size == 1, \"Failed method: 'loss' in CrossEntropyLoss\\tIncorrect loss shape\"\n",
    "assert ce_diff.shape == pred.shape, \"Failed method: 'diff_loss' in CrossEntropyLoss\\tIncorrect diff_loss shape\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit test\n",
    "Now, we will use unittest library to test the values of returned arrays. For each of the classes defined below, the *setUp* method defines some necessary attributes, while the returned values will be compared in the following methods starting with 'test_'. \n",
    "\n",
    "Should your code fail to pass one of the tests, you'll see where the error has occurred. Since you have passed the shape test, it may not be due to shape issues. Instead, try to double-check if your code is mathematically correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FCLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestFullyConnectedLayer(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        import layer\n",
    "        in_dim, out_dim = 2, 4\n",
    "        self.layer = layer.FCLayer(in_dim, out_dim)\n",
    "        self.layer.weights.value = np.array([[0.5488135 , 0.71518937, 0.60276338, 0.54488318],\n",
    "                                             [0.4236548 , 0.64589411, 0.43758721, 0.891773  ]])\n",
    "        self.layer.bias.value = np.array([0.96366276, 0.38344152, 0.79172504, 0.52889492])[None, :]\n",
    "        self.delta_n = np.array([[0.5507979 , 0.70814782, 0.29090474, 0.51082761],\n",
    "                                 [0.89294695, 0.89629309, 0.12558531, 0.20724288]])\n",
    "        def reset_input():\n",
    "            self.layer.input_data = np.arange(4).reshape(2, 2)\n",
    "        self.reset_input = reset_input\n",
    "        \n",
    "    def test_forward(self):\n",
    "        X = np.arange(4).reshape(2, 2)\n",
    "        output = self.layer.forward(X)\n",
    "        answer = np.array([[1.38731756, 1.02933563, 1.22931225, 1.42066792],\n",
    "                           [3.33225417, 3.75150259, 3.31001342, 4.29398029]])\n",
    "        self.assertTrue(np.allclose(output, answer), \"(FCLayer) forward method failed!\")\n",
    "        \n",
    "    def test_backward(self):\n",
    "        self.layer.input_data = np.random.randn(2, 2) # ignore this\n",
    "        output = self.layer.backward(self.delta_n)\n",
    "        answer = np.array([[1.26243321, 1.27357515],\n",
    "                           [1.31970202, 1.19697982]])\n",
    "        self.assertTrue(np.allclose(output, answer), \"(FCLayer) backward method failed!\")\n",
    "    \n",
    "    def test_gradient(self):\n",
    "        self.reset_input()\n",
    "        self.layer.backward(self.delta_n)\n",
    "        dEdW = self.layer.weights.grad\n",
    "        dEdb = self.layer.bias.grad\n",
    "        w_answer = np.array([[1.7858939 , 1.79258618, 0.25117062, 0.41448576],\n",
    "                             [3.22963875, 3.39702709, 0.66766067, 1.13255625]])\n",
    "        b_answer = np.array([[1.44374485, 1.60444091, 0.41649005, 0.71807049]])\n",
    "        self.assertTrue(np.allclose(dEdW, w_answer), \"(FCLayer) Incorrect gradient for weights!\")\n",
    "        self.assertTrue(np.allclose(dEdb, b_answer), \"(FCLayer) Incorrect gradient for bias!\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestActivation(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        import activation\n",
    "        from utils import sigmoid, sigmoid_prime\n",
    "        self.act = activation.Activation(sigmoid, sigmoid_prime)\n",
    "        def reset_input():\n",
    "            self.act.input_data = np.array([[1.38731756, 1.02933563, 1.22931225, 1.42066792],\n",
    "                                              [3.33225417, 3.75150259, 3.31001342, 4.29398029]])\n",
    "        self.reset_input = reset_input\n",
    "        self.delta_n = np.array([[0.5507979 , 0.70814782, 0.29090474, 0.51082761],\n",
    "                                 [0.89294695, 0.89629309, 0.12558531, 0.20724288]])\n",
    "        \n",
    "    def test_forward(self):\n",
    "        X = np.arange(4).reshape(2, 2)\n",
    "        output = self.act.forward(X)\n",
    "        answer = np.array([[0.5       , 0.73105858],\n",
    "                           [0.88079708, 0.95257413]])\n",
    "        self.assertTrue(np.allclose(output, answer), \"(Activation) forward method failed!\")\n",
    "    \n",
    "    def test_backward(self):\n",
    "        self.reset_input()\n",
    "        output = self.act.backward(self.delta_n)\n",
    "        answer = np.array([[0.08807356, 0.13733244, 0.05093431, 0.08004899],\n",
    "                           [0.02972813, 0.02009243, 0.00426841, 0.00275329]])\n",
    "        self.assertTrue(np.allclose(output, answer), \"(Activation) backward method failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMSELoss(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        from loss import MSELoss\n",
    "        self.loss = MSELoss()\n",
    "        self.target = np.array([3, 9, 8, 9, 8, 7, 2, 7, 8, 5])[:, None]\n",
    "        self.pred = np.arange(10).reshape(10, 1)\n",
    "\n",
    "    def test_mse_loss(self):\n",
    "        output = self.loss.loss(self.pred, self.target)\n",
    "        answer = 9.85\n",
    "        self.assertTrue(np.isclose(output, answer), \"(MSELoss) Incorrect loss value!\")\n",
    "        \n",
    "    def test_mse_loss_differentiated(self):\n",
    "        output = self.loss.diff_loss(self.pred, self.target)\n",
    "        answer = np.array([-0.3, -0.8, -0.6, -0.6, -0.4, -0.2, 0.4, 0., 0., 0.4])[:, None]\n",
    "        self.assertTrue(np.allclose(output, answer), \"(MSELoss) Incorrect derivative!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCrossEntropyLoss(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        from loss import CrossEntropyLoss\n",
    "        self.loss = CrossEntropyLoss()\n",
    "        self.pred = np.array([[0.08289002, 0.84846525, 0.10360399, 0.97278462],\n",
    "                              [0.42144156, 0.2212615 , 0.19189267, 0.94363419],\n",
    "                              [0.29702955, 0.44302759, 0.09034213, 0.26492577],\n",
    "                              [0.09610541, 0.37157434, 0.76826065, 0.22563809]])\n",
    "        self.target = np.array([[0., 1., 0., 0.],\n",
    "                                [1., 0., 0., 0.],\n",
    "                                [0., 0., 0., 1.],\n",
    "                                [0., 0., 1., 0.]])\n",
    "    \n",
    "    def test_ce_loss(self):\n",
    "        output = self.loss.loss(self.pred, self.target)\n",
    "        answer = 5.000648850895981\n",
    "        self.assertTrue(np.isclose(output, answer), \"(CrossEntropyLoss) Incorrect loss value!\")\n",
    "    \n",
    "    def test_ce_loss_differentiated(self):\n",
    "        output = self.loss.diff_loss(self.pred, self.target)\n",
    "        answer = np.array([[ 0.15137676, -0.67450502,  0.15454507,  0.36858318],\n",
    "                           [-0.76739833,  0.19040386,  0.18489323,  0.39210124],\n",
    "                           [ 0.25387967,  0.29378802,  0.20647369, -0.75414138],\n",
    "                           [ 0.18470979,  0.24329016, -0.63825443,  0.21025447]])\n",
    "        self.assertTrue(np.allclose(output, answer), \"(CrossEntropyLoss) Incorrect derivative!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nesterov Accelerated Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestNesterov(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        from optim import SGD\n",
    "        from param import Parameter\n",
    "        self.w = Parameter(value=np.array([[0.1980958 , 0.71222462], [0.5550827 , 0.74202243]]))\n",
    "        self.w.grad = np.array([[0.14945974, 0.91003691], [0.65230119, 0.56729758]])\n",
    "        parameters = [self.w]\n",
    "        self.optimizer = SGD(parameters, lr=0.1, nesterov=True, mu=0.9)\n",
    "        self.w.velocity = np.array([[0.50626091, 0.34927326], [0.64485252, 0.14303997]])\n",
    "        \n",
    "    def test_nag_step(self):\n",
    "        self.optimizer.step()\n",
    "        val = self.w.value\n",
    "        answer = np.array([[0.57976979, 0.82222895],\n",
    "                           [0.95347602, 0.75009827]])\n",
    "        self.assertTrue(np.allclose(val, answer), \"(SGD) Incorrect Nesterov update!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suite():\n",
    "    suite = unittest.TestSuite()\n",
    "    suite.addTest(TestFullyConnectedLayer('test_forward'))\n",
    "    suite.addTest(TestFullyConnectedLayer('test_backward'))\n",
    "    suite.addTest(TestFullyConnectedLayer('test_gradient'))\n",
    "    suite.addTest(TestActivation('test_forward'))\n",
    "    suite.addTest(TestActivation('test_backward'))\n",
    "    suite.addTest(TestMSELoss('test_mse_loss'))\n",
    "    suite.addTest(TestMSELoss('test_mse_loss_differentiated'))    \n",
    "    suite.addTest(TestCrossEntropyLoss('test_ce_loss'))\n",
    "    suite.addTest(TestCrossEntropyLoss('test_ce_loss_differentiated'))\n",
    "    suite.addTest(TestNesterov('test_nag_step'))\n",
    "    return suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_forward (__main__.TestFullyConnectedLayer) ... ok\n",
      "test_backward (__main__.TestFullyConnectedLayer) ... ok\n",
      "test_gradient (__main__.TestFullyConnectedLayer) ... ok\n",
      "test_forward (__main__.TestActivation) ... ok\n",
      "test_backward (__main__.TestActivation) ... ok\n",
      "test_mse_loss (__main__.TestMSELoss) ... ok\n",
      "test_mse_loss_differentiated (__main__.TestMSELoss) ... ok\n",
      "test_ce_loss (__main__.TestCrossEntropyLoss) ... ok\n",
      "test_ce_loss_differentiated (__main__.TestCrossEntropyLoss) ... ok\n",
      "test_nag_step (__main__.TestNesterov) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 10 tests in 0.024s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    runner = unittest.TextTestRunner(verbosity=3)\n",
    "    runner.run(suite())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
